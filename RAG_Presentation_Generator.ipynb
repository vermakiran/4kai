{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vermakiran/4kai/blob/main/RAG_Presentation_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3JFx-GGqSqu",
        "outputId": "0761a566-9233-41bc-fe6d-a93bc49249fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3 pandoc-data\n",
            "Suggested packages:\n",
            "  texlive-latex-recommended texlive-xetex texlive-luatex pandoc-citeproc\n",
            "  texlive-latex-extra context wkhtmltopdf librsvg2-bin groff ghc nodejs php\n",
            "  python ruby libjs-mathjax libjs-katex citation-style-language-styles\n",
            "The following NEW packages will be installed:\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3 pandoc\n",
            "  pandoc-data\n",
            "0 upgraded, 4 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 20.6 MB of archives.\n",
            "After this operation, 156 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [115 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm-extensions0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [25.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc-data all 2.9.2.1-3ubuntu2 [81.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc amd64 2.9.2.1-3ubuntu2 [20.3 MB]\n",
            "Fetched 20.6 MB in 3s (8,204 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libcmark-gfm0.29.0.gfm.3:amd64.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../libcmark-gfm0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcmark-gfm-extensions0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../libcmark-gfm-extensions0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package pandoc-data.\n",
            "Preparing to unpack .../pandoc-data_2.9.2.1-3ubuntu2_all.deb ...\n",
            "Unpacking pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package pandoc.\n",
            "Preparing to unpack .../pandoc_2.9.2.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Setting up libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Setting up pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: pypandoc\n",
            "Successfully installed pypandoc-1.15\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "\n",
        "!sudo apt install pandoc\n",
        "!pip install pypandoc\n",
        "!pip install torch\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install langchain-huggingface\n",
        "!pip install langchain-vectorstores\n",
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install transformers\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm #https://pypi.org/project/colab-xterm/\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "t6IIRc2Lrfdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pypandoc\n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "from tqdm import tqdm, trange\n",
        "from typing import List, Dict, Any\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence, RunnableLambda\n",
        "from langchain.schema import BaseOutputParser\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "HflbV79wtN1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging configuration\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger.setLevel(logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.disabled = True\n",
        "#logger.disabled = False\n",
        "\n",
        "class PresentationGenerator:\n",
        "    def __init__(self, pdf_path: str, output_file: str, ollama_model: str = \"gemma2:9b\", topic: str = \"general\", output_format: list[str] = [\"pptx\"]):\n",
        "        self.pdf_path = pdf_path\n",
        "        self.output_file = f\"{output_file}.md\"\n",
        "        self.output_format = output_format\n",
        "        self.persist_directory = f\"./chromadb_{topic}\"\n",
        "        self.collection_name = f\"slidev_content_{topic}\"\n",
        "        self.topic = topic\n",
        "        self.llm = Ollama(model=ollama_model)\n",
        "\n",
        "        # Load the model and tokenizer with AutoModel\n",
        "        model = AutoModel.from_pretrained(\n",
        "            'intfloat/multilingual-e5-large',\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\"  # Use \"auto\" to assign to GPU if available\n",
        "        )\n",
        "\n",
        "        encode_kwargs = {'normalize_embeddings': True}\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            client=model,  # Pass the loaded model to HuggingFaceEmbeddings\n",
        "            encode_kwargs=encode_kwargs\n",
        "        )\n",
        "\n",
        "        self.vectordb = None\n",
        "        self.initialize_chains()\n",
        "\n",
        "    def load_and_process_pdf(self) -> List:\n",
        "        loader = PyPDFLoader(file_path=self.pdf_path)\n",
        "        documents = loader.load()\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
        "        return text_splitter.split_documents(documents)\n",
        "\n",
        "    def create_or_load_vectordb(self):\n",
        "        # Check if a database already exists for the topic\n",
        "        if os.path.exists(self.persist_directory):\n",
        "            logger.info(f\"Loading existing database for the topic: {self.topic}\")\n",
        "            self.vectordb = Chroma(\n",
        "                persist_directory=self.persist_directory,\n",
        "                embedding_function=self.embeddings,\n",
        "                collection_name=self.collection_name\n",
        "            )\n",
        "            # Check if the PDF has already been indexed\n",
        "            if self.vectordb.get(where={\"source\": self.pdf_path}):\n",
        "                logger.info(f\"The PDF '{self.pdf_path}' already exists in the database for the topic '{self.topic}'.\")\n",
        "                return\n",
        "\n",
        "        # If not, or if the PDF is not indexed, create/update the database\n",
        "        logger.info(f\"Creating/updating database for the topic: {self.topic}\")\n",
        "        texts = self.load_and_process_pdf()\n",
        "        logger.info(f\"Processed texts: {len(texts)} fragments\")\n",
        "\n",
        "        # Add the PDF path as metadata for future checks\n",
        "        for text in texts:\n",
        "            text.metadata[\"source\"] = self.pdf_path\n",
        "\n",
        "        self.vectordb = Chroma.from_documents(\n",
        "            documents=texts,\n",
        "            embedding=self.embeddings,\n",
        "            persist_directory=self.persist_directory,\n",
        "            collection_name=self.collection_name\n",
        "        )\n",
        "\n",
        "    def initialize_chains(self):\n",
        "        self.outline_prompt = PromptTemplate(\n",
        "            input_variables=[\"topics\", \"tone\"],\n",
        "            template=\"\"\"\n",
        "                      Generate a presentation outline based on the following topics: {topics}\n",
        "                      The overall tone of the presentation should be: {tone}\n",
        "                      For each topic, provide a main title and create multiple slides as needed. Each slide should have a subtitle and a brief description that captures the essence of the content. Avoid overcrowding slides with too much text.\n",
        "                      The outline should have a logical sequence and coherent argumentation, maintaining thematic consistency across slides within each topic.\n",
        "                      Output format:\n",
        "\n",
        "                      1 [Title 1]\n",
        "                      Description: [Brief description of the slide content]\n",
        "                      2 [Title 2]\n",
        "                      Description: [Brief description of the slide content]\n",
        "                      ...\n",
        "\n",
        "                      Continue this format for all topics, ensuring a sequential and thematically coherent presentation structure.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        self.slide_prompt = PromptTemplate(\n",
        "            input_variables=[\"title\", \"description\", \"context\", \"tone\"],\n",
        "            template=\"\"\"\n",
        "            Generate a slide in Markdown format for a presentation with the following title and description:\n",
        "            Title: {title}\n",
        "            Description: {description}\n",
        "\n",
        "            Additional context: {context}\n",
        "            General tone of the presentation: {tone}\n",
        "\n",
        "            The slide should be consistent with the provided title and description, and maintain the overall tone of the presentation.\n",
        "\n",
        "            Slide format:\n",
        "            ## {title}\n",
        "\n",
        "            [Slide content in Markdown]\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        self.evaluation_prompt = PromptTemplate(\n",
        "            input_variables=[\"slide_content\", \"goal\"],\n",
        "            template=\"\"\"\n",
        "            Evaluate whether the following slide meets the established goal:\n",
        "            Slide:\n",
        "            {slide_content}\n",
        "\n",
        "            Goal: {goal}\n",
        "\n",
        "            Does the slide meet the goal? Answer with 'Yes' or 'No' and provide a brief justification.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        self.final_evaluation_prompt = PromptTemplate(\n",
        "            input_variables=[\"slide_content\", \"title\", \"description\"],\n",
        "            template=\"\"\"\n",
        "            Evaluate whether the following slide is significant given the provided title and description, avoiding slides with content like: \"I propose a draft\" or \"Here is a possible version of the slide\", \"etcetera\"\n",
        "            Title: {title}\n",
        "            Description: {description}\n",
        "            Slide:\n",
        "            {slide_content}\n",
        "\n",
        "            Is the slide significant? Answer with 'Yes' or 'No' and provide a brief justification.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        self.outline_chain = self.outline_prompt | self.llm | RunnableLambda(lambda x: {\"output\": x})\n",
        "        self.slide_chain = self.slide_prompt | self.llm\n",
        "        self.evaluation_chain = self.evaluation_prompt | self.llm | YesNoOutputParser() | RunnableLambda(lambda x: {\"output\": x})\n",
        "        self.final_evaluation_chain = self.final_evaluation_prompt | self.llm | YesNoOutputParser() | RunnableLambda(lambda x: {\"output\": x})\n",
        "\n",
        "    def generate_presentation_outline(self, topics: List[str], tone: str) -> List[Dict[str, str]]:\n",
        "        outline_response = self.outline_chain.invoke({\"topics\": \", \".join(topics), \"tone\": tone})\n",
        "        logger.info(f\"Outline generated (response): {outline_response}\")\n",
        "\n",
        "        outline_text = outline_response['output']\n",
        "        parsed_outline = self.parse_outline(outline_text)\n",
        "\n",
        "        logger.info(f\"Outline generated (parsed): {parsed_outline}\")\n",
        "        return parsed_outline\n",
        "\n",
        "    def parse_outline(self, text: str) -> List[Dict[str, str]]:\n",
        "        lines = text.strip().split(\"\\n\")\n",
        "        outline = []\n",
        "        current_item = {}\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip().startswith(\"**\") and line.strip().endswith(\"**\"):\n",
        "                if current_item:\n",
        "                    outline.append(current_item)\n",
        "                current_item = {\"title\": line.strip(\"** \").strip(), \"description\": \"\"}\n",
        "            elif line.strip().startswith(\"Description:\"):\n",
        "                if current_item:\n",
        "                    current_item[\"description\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "        if current_item:\n",
        "            outline.append(current_item)\n",
        "\n",
        "        logger.info(f\"Outline parsed: {outline}\")\n",
        "        return outline\n",
        "\n",
        "    def generate_slide(self, title: str, description: str, tone: str) -> str:\n",
        "        context = self.vectordb.similarity_search(title, k=3)\n",
        "        context_text = \"\\n\".join([doc.page_content for doc in context])\n",
        "        logger.info(f\"Context for {title}: {context_text}\")\n",
        "\n",
        "        for _ in range(5):  # Maximum 5 attempts\n",
        "            slide_content = self.slide_chain.invoke({\n",
        "                \"title\": title,\n",
        "                \"description\": description,\n",
        "                \"context\": context_text,\n",
        "                \"tone\": tone\n",
        "            })\n",
        "            logger.info(f\"Slide content generated for {title}: {slide_content}\")\n",
        "            evaluation_result = self.evaluation_chain.invoke({\"slide_content\": slide_content, \"goal\": description})\n",
        "\n",
        "\n",
        "\n",
        "            evaluation = evaluation_result['output']['evaluation']\n",
        "            justification = evaluation_result['output']['justification']\n",
        "\n",
        "            if evaluation:\n",
        "                return slide_content\n",
        "\n",
        "            context_text += f\"\\nSuggested improvement: {justification}\"\n",
        "            logger.info(f\"Retrying generation for {title} with improvement: {justification}\")\n",
        "\n",
        "        return slide_content\n",
        "\n",
        "    def final_evaluation(self, slides: List[Dict[str, str]]) -> List[str]:\n",
        "        significant_slides = []\n",
        "\n",
        "        for slide in slides:\n",
        "            slide_content = slide[\"slide_content\"]\n",
        "            title = slide[\"title\"]\n",
        "            description = slide[\"description\"]\n",
        "            evaluation_result = self.final_evaluation_chain.invoke({\"slide_content\": slide_content, \"title\": title, \"description\": description})\n",
        "\n",
        "            if evaluation_result['output']['evaluation']:\n",
        "                significant_slides.append(slide_content)\n",
        "            else:\n",
        "                logger.warning(f\"Slide removed: {title} - {evaluation_result['output']['justification']}\")\n",
        "\n",
        "        return significant_slides\n",
        "\n",
        "    def generate_full_presentation(self, topics: List[str], tone: str) -> None:\n",
        "        self.create_or_load_vectordb()\n",
        "        outline = self.generate_presentation_outline(topics, tone)\n",
        "        all_slides = []\n",
        "\n",
        "        for slide in outline:\n",
        "            if 'title' in slide and 'description' in slide:\n",
        "                slide_content = self.generate_slide(slide['title'], slide['description'], tone)\n",
        "                all_slides.append({\n",
        "                    \"title\": slide['title'],\n",
        "                    \"description\": slide['description'],\n",
        "                    \"slide_content\": slide_content\n",
        "                })\n",
        "            else:\n",
        "                logger.warning(f\"Incomplete slide found: {slide}\")\n",
        "\n",
        "        if not all_slides:\n",
        "            logger.error(\"No slides were generated.\")\n",
        "            return\n",
        "\n",
        "        significant_slides = self.final_evaluation(all_slides)\n",
        "\n",
        "        with open(self.output_file, \"w\") as f:\n",
        "            f.write(\"\\n\\n---\\n\\n\".join(significant_slides))\n",
        "\n",
        "        logger.info(f\"Presentation generated and saved in {self.output_file}\")\n",
        "\n",
        "        for fmt in self.output_format:\n",
        "            output_document = f\"{self.output_file}.{fmt}\"  # Create the output file name based on the format\n",
        "            output = pypandoc.convert_file(\n",
        "                self.output_file,\n",
        "                fmt,\n",
        "                outputfile=output_document,\n",
        "                extra_args=['-V', 'mainfont=\"Arial\"', '-V', 'fontsize=\"24\"', '-V', 'fontcolor=\"FF0000\"']\n",
        "            )\n",
        "\n",
        "        assert output == \"\"\n",
        "        logger.info(\"The presentation has been successfully created in PPTX format.\")\n",
        "\n",
        "class OutlineParser(BaseOutputParser):\n",
        "    def parse(self, text: str) -> List[Dict[str, str]]:\n",
        "        if isinstance(text, list):\n",
        "            return text\n",
        "\n",
        "        lines = text.strip().split(\"\\n\")\n",
        "        outline = []\n",
        "        current_item = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\"**\") and line.endswith(\"**\"):\n",
        "                # Detected a new title\n",
        "                if current_item:\n",
        "                    outline.append(current_item)\n",
        "                title_text = line.strip(\"** \").strip()\n",
        "                current_item = {\"title\": title_text, \"description\": \"\"}\n",
        "            elif \"Description:\" in line:\n",
        "                if current_item:\n",
        "                    # Append description to the current item\n",
        "                    description_text = line.split(\"Description:\", 1)[1].strip()\n",
        "                    current_item[\"description\"] += description_text\n",
        "            elif current_item and line.startswith(\"*\"):\n",
        "                # Handling indented descriptions or additional lines\n",
        "                current_item[\"description\"] += \" \" + line.strip(\"*\").strip()\n",
        "\n",
        "        # Append the last item if it exists\n",
        "        if current_item:\n",
        "            outline.append(current_item)\n",
        "\n",
        "        return outline\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"outline\"\n",
        "\n",
        "\n",
        "class YesNoOutputParser(BaseOutputParser):\n",
        "    def parse(self, text: str) -> Dict:\n",
        "        text = text.strip().lower()\n",
        "        if \"yes\" in text:\n",
        "            return {\"evaluation\": True, \"justification\": text.split(\"yes\", 1)[1].strip()}\n",
        "        elif \"no\" in text:\n",
        "            return {\"evaluation\": False, \"justification\": text.split(\"no\", 1)[1].strip()}\n",
        "        else:\n",
        "            return {\"evaluation\": False, \"justification\": \"no justification\"}\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"yes_no\""
      ],
      "metadata": {
        "id": "I8sIotpwtN6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Define the directory paths\n",
        "base_dir = 'references'\n",
        "documents_dir = 'documents'\n",
        "\n",
        "# Create the directories if they don't exist\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "os.makedirs(documents_dir, exist_ok=True)\n",
        "\n",
        "# Define the URL for the PDF and the local file path\n",
        "pdf_url = \"https://assets.openstax.org/oscms-prodcms/media/documents/Principles_Marketing-WEB.pdf\"\n",
        "pdf_path = os.path.join(base_dir, \"Principles_Marketing-WEB.pdf\")\n",
        "\n",
        "# Download the PDF if it doesn't already exist\n",
        "if not os.path.exists(pdf_path):\n",
        "    print(f\"Downloading {pdf_path}...\")\n",
        "    response = requests.get(pdf_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    if response.status_code == 200:\n",
        "        with open(pdf_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Downloaded {pdf_path} successfully.\")\n",
        "    else:\n",
        "        print(f\"Failed to download {pdf_path}. Status code: {response.status_code}\")\n",
        "else:\n",
        "    print(f\"{pdf_path} already exists.\")\n"
      ],
      "metadata": {
        "id": "SrjrS8ubtN9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "qDLAzVBIsC6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1t83IGKgTB-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#curl -fsSL https://ollama.com/install.sh | sh\n",
        "#ollama serve &\n",
        "#ollama pull gemma2:9b"
      ],
      "metadata": {
        "id": "X4wUGKcSsKEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Use the presentation generator\n",
        "pdf_path = \"references/Principles_Marketing-WEB.pdf\"\n",
        "output_file = \"documents/Introduction_MKT_007\"\n",
        "ollama_model = \"gemma2:9b\"\n",
        "topics = [\"What is Marketing?\",\n",
        "          \"The Marketing Process\",\n",
        "          \"The Marketing Mix and the 4 Ps\",\n",
        "          \"Strategic Planning in Marketing\",\n",
        "          \"Developing a Strategic Marketing Plan\", \"Conclusions\"]\n",
        "tone = \"Educational and clear, focused on explaining concepts in a way that is accessible to beginners.\"\n",
        "topic = \"marketing\"\n",
        "output_format = [\"pptx\", \"docx\"]\n",
        "\n",
        "generator = PresentationGenerator(pdf_path, output_file, ollama_model, topic, output_format)\n",
        "generator.create_or_load_vectordb()\n",
        "generator.generate_full_presentation(topics, tone)\n",
        "\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"The process took {elapsed_time:.4f} seconds to execute.\")"
      ],
      "metadata": {
        "id": "crWL834vtN_b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}